Node:启动一个elasticsearch实例就是启动一个node，互联节点的集合就是cluster。每个node都知道集群中所有其他node，
并可以转发客户端的请求到合适的节点上。
默认有以下几种类型的节点：master,data,ingest,machine learning.
1)master node:一个节点将node.master设为true，这使得它有资格被选为master节点，可以控制集群。
2)data node:将node.data设置为true，data node持有数据，并执行数据相关操作如CRUD，搜索和聚合操作。
3)ingest node:将node.ingest设为true,此节点可以对文档应用ingest pipeline，可以被索引之前转换和丰富文档。由于
负载较重，因此最好有专门的ingest node，并把master node和data node中的配置node.ingest设为false.

**coordinating node(协调节点):搜索请求和批量索引请求都可能涉及到多个数据节点上的数据。
对于一个Search request，通常会有两个阶段，这都是被协调节点协调的。
在scatter phase(分散)，协调节点转发请求到持有目标数据的数据节点。每个数据节点本地执行请求，之后返回结果到协调节点。
在gather phase(聚合)，协调节点reduce每个数据节点的结果为一个完整的结果集。（类似于大数据中map--reduce的过程）
每个节点都可以认为是一个协调节点。这就意味着把node.master,node.data,node.ingest三个设置都设为false的节点将只担任
协调节点的角色。这种情况下，这个协调节点需要有足够的内存和CPU来处理gather phase阶段的任务。

Master node：master节点负责集群范围内的轻量级操作，例如创建或删除index，追踪哪些节点是集群的一部分，决定哪个分片分配到
哪个节点上。有一个稳定的master节点对于集群健康来说很重要。
**master节点必须有访问data/目录的权限，就像data节点一样。因为在这个目录下持久化了集群的状态。

索引和搜索数据是CPU，内存和IO密集型的工作，会对节点的资源造成压力。为了确保master节点稳定，有专门的master节点和data节点比较好。
master节点也可以作为协调节点，路由来自客户端的索引和搜索请求到data节点。但是最好不要让master节点做这些协调工作。因为为了维持
集群的稳定，master节点做的工作越少越好。


HA高可用的集群需要至少三个master资格节点，它们中至少有两个不是voting-only节点。这样这个集群才能选出一个master节点，即使其中一个宕机。


DATA Node：数据节点持有分片，这些分片包含已经索引的文档。数据节点处理数据相关的操作，比如CRUD，搜索和聚合操作。
这些操作是IO，内存，CPU密集型的。监控这些资源，当这些数据节点过载时增加更多的数据节点是很重要的。
有专用的数据节点的好处是分开了master和data角色。


Ingest Node：执行一些预处理的任务。

**只做协调功能的节点不是越多越好，data节点也可以充当协调的角色。


data node在硬盘上维护的数据：
1）分配到该节点的每个分片的分片数据
2）分配到该节点的每个分片对应的索引元数据。
3）集群范围内的元数据，比如配置和索引模板。

master node在硬盘上维护的数据:
1)集群中每个索引的元数据
2）集群范围内的元数据，比如配置和索引模板。
每个节点在启动时都会检查它的数据路径的内容。如果发现异常数据会拒绝启动。
比如，node.data设为false的节点如果发现硬盘上有任何分片数据会拒绝启动。



主分片的数量在索引创建的时候就确定了，但是副分片的数量在任何时候都可以改变，并且不会影响索引和查询操作。
分片的大小和主分片的数量之间的平衡：分片越多，维护索引的开销越大。分片越大，当elasticSearch需要再平衡
集群时在节点之间移动分片花费的时间越长。



读写文档：
在elasticSerach中，每个索引被分成多个分片，每个分片有多个副本。
在文档增加或移除时，这些副本必须保持同步，否则会导致数据不一致。
保持分片副本同步，并使它们提供读操作被称作data replication model.
elasticSearch的数据复制模型是基于主-备模型。主分片是所有索引操作的入口。主分片负责同步数据给其他副本。

***基本的写模型：在elasticSerach中，每个索引操作会通过routing到一个replication group，通常是基于document ID。
一旦确定了replication group，这个索引操作会在内部被转发到这个组中的当前主分片。主分片负责校验操作并同步给其他副本。
因为有些副本可能处于离线状态，因此主分片不需要同步到所有的副本。elasticSerach维护了一个应当接收操作的分片副本列表。
这个列表被称作in-sync copies，并且是由master节点维护的。
主分片的工作流如下：
1.Validate incoming operation and reject it if structurally invalid (Example: have an object field where a number is expected)
2.Execute the operation locally i.e. indexing or deleting the relevant document. This will also validate the content of fields and reject if needed (Example: a keyword value is too long for indexing in Lucene).
3.Forward the operation to each replica in the current in-sync copies set. If there are multiple replicas, this is done in parallel.
4.Once all replicas have successfully performed the operation and responded to the primary, the primary acknowledges the successful completion of the request to the client.

****错误处理
当主分片本身失败，则此主分片所在节点会发送信息通知master节点。当前索引操作会等待主节点重新选一个副本作为新的主分片。
之后索引操作会被转发到新的主分片处理。注意，master也会监控各个节点的健康状况并可能主动降级主分片。这一般发生在
持有主分片的节点由于网络问题与集群失连的情况。
一旦在主分片上执行成功，主分片要处理在副本分片上执行可能出现的错误。副本分片出错，主分片会发送消息到master节点请求
把出错的分片从in-sync中移除。只有master节点确认移除，主分片才会向客户端确认当前操作。注意，master节点也会告知
另一个节点开启一个新的分片副本来恢复系统健康。

当转发操作到其他分片副本时，主分片也会校验自己是否仍然是活跃的主分片。如果主分片由于网络分区（或长时间GC）已经与
其他副分片隔离，在它自己意识到它被降级之前它仍会继续处理接下来的索引操作。
来自过时的主分片转发的操作会被其他副分片拒绝。当主分片从副分片得到的响应说拒绝它的请求是因为它不再是主分片时，
主分片会联系master节点然后了解到它已经被取代。索引操作之后会被路由到新的主分片。

***如果没有副分片了怎么办？
这种情况是可能发生的，当索引配置没有副本分片或仅仅是因为所有的副本分片都宕机不可用。
这种情况下，主分片在没有任何外部校验的情况下处理操作，看起来是有问题的。另一方面，主分片不能自己fail其他的副分片，
而是请求master节点替它这么做。这就意味着master节点知道当前主分片是唯一有效的分片。我们会保证master不会提议任何
其他过期的分片称为新的主分片，这样任何进入当前主分片的操作就不会丢失。当然，因为当前只有一个分片在运行，物理硬件的问题
可以导致数据丢失。

***基本读模型：
elasticSerach读可以是非常轻量级的通过ID查询，也可以是复杂的、耗CPU的聚合搜索请求。
主--备模型的优点之一就是它可以保证所有的分片备份都一样。这样的话，一个in-sync的备份就可以服务读请求了。
当一个节点接收到读请求，它负责把请求转发到持有目标分片的节点上，整理响应内容，之后响应客户端。
工作流程如下：
1.解析读请求到相关的分片。注意到大部分的搜索会涉及到多个索引，需要从多个分片中读取数据，每个代表数据的不同子集。
2.选择每个相关分片其中的一个活跃分片，可以是主分片也可以是副分片。默认，elasticSerach会在分片组上简单的轮询。
3.向被选中的分片发送读请求。
4.整合结果并响应客户端。注意到，如果是根据ID进行查询的情况，只会有一个分片，此步骤可以省略。

**错误：
1.单个分片可以降低索引的速度
因为主分片的每个索引操作都会等待in-sync中的副本同步完成。因此单个慢速分片会影响整个分片组的性能。
多个分片副本可以提高读操作的效率，但是也可能降低了写的效率。
2.脏读
一个网络隔离的主分片也会收到写请求，但是不会被确认。这是因为，主分片只有当发送请求到它的副分片或发送消息到
master节点才会意识到自己网络隔离了。但是此时索引操作已经在主分片上成功了，可能会被并发读读取到。elasticSerach通过
每秒钟pinging master，如果master没有回应则拒绝索引操作来降低脏读风险。


参数解析：
1）wait for active shards
为了提高写操作的效率，索引操作可以通过配置在继续操作之前等待特定数量的活跃分片。如果配置数量的活跃分片不可用，则写
操作必须等待和重试，直到必要的分片数量开始或超时出现。默认情况下，写操作只等待主分片，主分片成功则继续执行操作。也就是
wait_for_active_shards=1。这个默认值可以被重写，在索引设置时动态配置index.write.wait_for_active_shards。
只在每次操作时改变这个行为，可以使用wait_for_active_shards请求参数。
这个配置的有效值是all或任何正整数，最大不超过每个分片组的总数（number_of_replicas+1,也就是副分片数加上一个主分片）。
指定负数或更大的值都会抛出错误。
例如，假设我们有一个3个节点的集群，分别是A，B，C。我们创建有3个副本的索引，也就是有四个分片备份。如果我们尝试
索引操作，默认情况下只需要确认每个分片的主分片可用就可以继续了。这就是意味着即使B和C都挂了，只要持有主分片的A正常，
这个索引操作就会继续，导致只有一份数据备份。如果wait_for_active_shards被设置到3，则索引操作需要3个活跃分片，这就需要集群中
有三个活跃节点，每个节点持有一个分片备份。然而，如果wait_for_active_shard设置为all（也就是4），则索引操作将不会进行，因为
我们没有四个分片备份。这个操作将会超时，除非一个新的节点启动，持有第四个分片备份。
值得注意的是，这个设置极大的减少了写操作没有写到必须数量的分片备份中。但是这并没有完全消除可能性，因为这个检查是在
写操作开始之前。一旦写操作开始执行，还是有可能在分片副本上同步错误，但是在主分片上成功。


自动索引创建：
索引操作会自动创建一个索引，如果这个索引之前不存在，并应用之前配置的索引模板。索引操作还会创建一个动态mapping如果之前不存在。
默认情况下，如果需要的话，新的字段和对象会被自动的添加到mapping定义中。
自动索引创建是通过action.auto_create_index配置的。这个配置默认是true，意味着索引总是自动创建。通过使用模式匹配来限定
那些索引可以被自动创建。如果设置为false则会完全被禁止。
 "persistent": {
        "action.auto_create_index": "twitter,index10,-index1*,+ind*" 
    }
自动ID生成：
索引操作可以在没有指定id的情况下被执行。这种情况下，id会自动生成。


路由：
默认情况下，路由是通过使用document id的哈希值。如果需要更明确的控制，可以使用routing参数


***Get API:
realtime:默认情况下，get API是实时的，不受索引刷新频率的影响（刷新后数据才对搜索可见）。
如果一个文档被更新之后还没被刷新，则get API会立刻发起一个刷新调用使得文档可见。这也会使得上次刷新之后的文档改变可见。
可以通过设置realtime参数为false禁止实时GET。


?refresh刷新：
Index,Update,Delete,Bulk API支持设置refresh参数控制什么时候这些请求导致的改变可以变得对于搜索可见。
refresh的取值可以为：
1）空字符串或true
在操作出现后立刻刷新相关的主副分片，因此被更新的文档可以立刻出现在搜索的结果中。
不过要仔细考虑和验证这样做会不会导致性能降低，从索引和搜索两方面考虑
2）wait_for
在搜索响应之前等待改变通过刷新变得可见。这个设置不会强制立刻刷新，而是等待刷新发生。elasticSearch会自动刷新分片每隔
index.refresh_interval，默认是1秒钟。这个设置是动态的。调用Refresh API或在index，update，delete等api上设置refresh为true都会
导致刷新。反过来导致正在等待的refresh设置为wait_for的请求返回，不用等待被动刷新。
3）false
不采取任何刷新相关动作。由这个请求导致的改变会在请求返回后的某个时间变得可见。

选择哪个值？
如果你必须让改变和请求同步的变得可见，你就必须在给elasticSearch更多压力（true)和等待更长时间（wait_for）。下面有些
参考点：
1）对索引做的改变越多，wait_for比true节省的工作量就越多。如果每隔index.refresh_interval改变一次，就没有差别。
2）true会创建很少的有效索引结构（会产生小的segments），必须之后被合并成更有效的索引结构（更大的segments).
就是说true的代价是在创建索引时间创建小的segment，在搜索时间搜索小的segment，在合并时间变成更大的segments.
3）不要连续启动多个refresh=wait_for请求。而是批量的把它们放进单个 refresh=wati_for bulk request.elasticSearch会并行的
启动它们并当它们都结束时返回。
4）如果refresh interval设置成-1,会禁止自动刷新。之后带有refresh=wait_for的请求会无限等待直到某些动作触发刷新。
相反，把index.refresh_interval设置小于默认值比如200ms将会使refresh=wait_for响应的更快，但是仍然会产生无效的segments.
5）refresh=wait_for只会影响当前正在运行的请求，但是强制立刻刷新refresh=true将会影响其他正在运行的请求。一般来说，如果你有
一个正在运行的系统，refresh=wait_for将不会过多影响系统。

**refresh=wait_for可以强制刷新
如果一个refresh=wait_for请求进来，并且当当前分片已经有index.max_refresh_listeners（默认1000)个请求等待刷新，
则这个请求就会想像把refresh设置为true，强制刷新。如果一个请求因为用尽listener slots导致刷新，则响应会包含
"forced_refresh":true.
